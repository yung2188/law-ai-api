import os
import requests
import json
from flask import Flask, request, Response
from tavily import TavilyClient

app = Flask(__name__)

# --- ç’°å¢ƒè®Šæ•¸ ---
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "tvly-dev-BqleJF10jLZhAIJHyvO050hVi3z")
ANYTHING_LLM_BASE_URL = os.environ.get("ANYTHING_LLM_URL", "https://ela-gravid-glenda.ngrok-free.dev")
ANYTHING_LLM_API_KEY = os.environ.get("ANYTHING_LLM_KEY", "ZPHEBVH-6RPMJ4M-NK5VP5D-H2X6DY5")
WORKSPACE_SLUG = os.environ.get("WORKSPACE_SLUG", "business_intelligence")

tavily = TavilyClient(api_key=TAVILY_API_KEY)

def get_ai_response(query):
    try:
        print(f"ğŸ” æ­£åœ¨æ·±åº¦æœå°‹: {query}")
        # A. Tavily æœå°‹ (å¢åŠ  max_results ä¸¦æå‡å…§å®¹é•·åº¦)
        search_response = tavily.search(query=query, search_depth="advanced", max_results=3)
        context = ""
        for r in search_response['results']:
            # å¢åŠ åˆ° 1000 å­—ï¼Œè®“ AI æœ‰æ›´å¤šç´ æ
            context += f"\nä¾†æº: {r['title']} ({r['url']})\nå…§å®¹: {r['content'][:1000]}\n"
        
        # B. AnythingLLM æ€è€ƒ (å„ªåŒ–è§’è‰²è¨­å®š)
        url = f"{ANYTHING_LLM_BASE_URL}/api/v1/workspace/{WORKSPACE_SLUG}/chat"
        headers = {
            "Authorization": f"Bearer {ANYTHING_LLM_API_KEY}",
            "Content-Type": "application/json",
            "ngrok-skip-browser-warning": "true"
        }
        
        # ğŸš€ å¼·å¤§çš„è§’è‰²è¨­å®š Prompt
        system_instruction = (
            "ä½ æ˜¯ä¸€ä½å°ˆæ¥­ä¸”è¦ªåˆ‡çš„ EaseMate AI åŠ©æ‰‹ã€‚è«‹éµå¾ªä»¥ä¸‹è¦å‰‡å›ç­”ï¼š\n"
            "1. ä½¿ç”¨ã€ç¹é«”ä¸­æ–‡ã€å›ç­”ï¼Œèªæ°£è¦è‡ªç„¶ã€åƒçœŸäººå°è©±ï¼Œä¸è¦å¤ªæ­»æ¿ã€‚\n"
            "2. é‡å°æœå°‹åˆ°çš„è³‡æ–™é€²è¡Œã€é‡é»æ‘˜è¦ã€ï¼Œä½¿ç”¨åˆ—é»æ–¹å¼è®“çµæ§‹æ¸…æ™°ã€‚\n"
            "3. å¦‚æœè³‡æ–™ä¸­æœ‰å…·é«”çš„æ•¸æ“šæˆ–æ³•å¾‹æ¢æ–‡ï¼Œè«‹å‹™å¿…ä¿ç•™ã€‚\n"
            "4. åœ¨å›ç­”æœ€å¾Œï¼Œè«‹åˆ—å‡ºåƒè€ƒçš„ä¾†æºé€£çµã€‚\n"
            "5. å¦‚æœæœå°‹ä¸åˆ°ç›¸é—œè³‡æ–™ï¼Œè«‹æ ¹æ“šä½ çš„çŸ¥è­˜åº«å›ç­”ï¼Œä¸¦èª å¯¦å‘ŠçŸ¥ã€‚"
        )
        
        full_prompt = f"{system_instruction}\n\nåƒè€ƒè³‡æ–™ï¼š\n{context}\n\nç”¨æˆ¶å•é¡Œï¼š{query}"
        payload = {"message": full_prompt, "mode": "chat"}
        
        response = requests.post(url, json=payload, headers=headers, timeout=120)
        
        if response.status_code == 200:
            return response.json().get("textResponse", "AI æš«æ™‚ç„¡æ³•å›ç­”")
        else:
            return f"AnythingLLM éŒ¯èª¤: {response.status_code}"
    except Exception as e:
        return f"ç³»çµ±ç•°å¸¸: {str(e)}"

@app.route("/research", methods=['POST'])
def research():
    data = request.json
    user_msg = data.get("keyword") or data.get("url")
    
    if not user_msg:
        result = {"report": "è«‹è¼¸å…¥æ‚¨æƒ³æŸ¥è©¢çš„å…§å®¹ã€‚"}
    else:
        answer = get_ai_response(user_msg)
        result = {"report": answer}
    
    response_json = json.dumps(result, ensure_ascii=False)
    return Response(response_json, content_type="application/json; charset=utf-8")

@app.route("/", methods=['GET'])
def index():
    return "EaseMate å¾Œç«¯å·²å•Ÿå‹•"

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 10000))
    app.run(host='0.0.0.0', port=port)
